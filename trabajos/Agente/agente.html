<!DOCTYPE html>
<html lang="es">
<head>
    <!--Elaborado por Julio Luengo Mendoza-->
    <meta charset="UTF-8">
    <title>Agente IA local | Portfolio Julio LM</title>
    <style>
        body {
            background: #222129;
            color: #f0bd8b;
            font-family: 'Courier New', Courier, monospace;
            margin: 0;
            padding: 5%;
        }
        header, main {
            max-width: 960px;
            margin: auto;
            padding: 32px 15px 0 15px;
        }
        .titulo-bloque {
            display: flex;
            align-items: center;
            margin-top: 32px;
        }
        .tag {
            background: #f0bd8b;
            color: #222129;
            padding: 8px 18px;
            font-weight: bold;
            margin-right: 12px;
            border-radius: 2px;
            letter-spacing: 0.5px;
        }
        .barra {
            flex: 1;
            height: 12px;
            background: repeating-linear-gradient(
                to right,
                #f0bd8b,
                #f0bd8b 2px,
                transparent 2px,
                transparent 8px
            );
        }
        h1 {
            margin-top: 28px;
            background: #1d1c23;
            padding: 36px 0;
            font-size: 2.1em;
            letter-spacing: 2px;
            border: 2px solid #f0bd8b;
            text-align: center;
        }
        h2, h3 {
            color: #f0bd8b;
            margin-top: 36px;
        }
        .fecha-autor {
            color: #c8a979;
            font-size: 1em;
            margin-bottom: 10px;
            text-align: right;
        }
        .autor-block {
            text-align: center;
            margin: 10px 0 42px 0;
        }
        .indice {
            margin: 32px 0 40px 0;
            padding: 24px;
            background: #1d1c23;
            border-left: 3px solid #f0bd8b;
            border-radius: 7px;
        }
        .indice a {
            display: block;
            color: #ffc686;
            margin-bottom: 9px;
            font-size: 1.12em;
            text-decoration: none;
        }
        .indice a:hover {
            text-decoration: underline;
        }
        section {
            border-top: 2px dotted #f0bd8b;
            margin-top: 30px;
            padding-top: 16px;
        }
        img {
            width: 100%;
            max-width: 550px;
            margin: 16px 0 5px 0;
            border: 2px solid #f0bd8b;
            background: #191821;
            box-shadow: 0 2px 18px rgba(100,90,50,0.08);
            display: block;
        }
        .pie-foto {
            color: #c8a979;
            font-size: 0.95em;
            margin-bottom: 14px;
            text-align: center;
        }
        nav {
            margin-bottom: 24px;
            text-align: left;
        }
        a.volver {
            color: #ffc686;
            text-decoration: none;
            font-size: 1.08em;
        }
        a.volver:hover {
            text-decoration: underline;
        }
        ul, ol {
            margin-left: 24px;
        }
        hr {
            border: 1px solid #f0bd8b;
            margin: 38px 0 28px 0;
        }
        .content-block {
            background: #24232a;
            border-radius: 6px;
            padding: 18px 26px;
            margin: 25px 0 0 0;
            box-shadow: 0 2px 18px rgba(110,100,56,0.07);
        }
        .code {
            background: #292832;
            color: #f0bd8b;
            padding: 6px 14px;
            border-radius: 4px;
            width: fit-content;
            font-size: 1.03em;
            font-family: inherit;
            margin: 8px 0;
            display: inline-block;
        }
        pre {
            background: #292832;
            color: #f0bd8b;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            border-left: 3px solid #f0bd8b;
            margin: 16px 0;
            font-size: 0.95em;
            line-height: 1.5;
        }
        .codigo {
            white-space: pre-wrap;
            background: #292832;
            border-left: 3px solid #f0bd8b;
            padding: 16px;
            margin: 16px 0;
            border-radius: 6px;
            font-size: 0.92em;
        }
        a {
            color: #ffc686;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .nota {
            background: #1d1c23;
            border: 1px solid #f0bd8b;
            padding: 16px;
            border-radius: 6px;
            margin: 16px 0;
        }
    </style>
</head>
<body>
    <header>
        <div class="titulo-bloque">
            <span class="tag"><a href="../../index.html">IA AVANZADA</a></span>
            <div class="barra"></div>
        </div>
        <h1>Agente IA Local GPU</h1>
    </header>
    
    <nav>
        <a href="../index.html" class="volver">← Volver al índice</a>
    </nav>
    
    <div class="autor-block">Elaborado por: Julio Luengo Mendoza</div>
    
    <div class="indice">
        <a href="#objetivo">OBJETIVO</a>
        <a href="#requisitos">REQUISITOS</a>
        <a href="#servidor">SERVIDOR IA</a>
        <a href="#opencode">OPENCODE</a>
        <a href="#pruebas">PRUEBAS GPU</a>
        <a href="#conclusiones">CONCLUSIONES</a>
    </div>

    <section id="objetivo">
        <h2>OBJETIVO</h2>
        <div class="content-block">
            Configurar agente OpenCode con IA local en NVIDIA RTX 5060 Ti (12GB VRAM) Windows 11. Backend Ollama API OpenAI-compatible en <span class="code">http://192.168.7.114:11434/v1</span>.<br><br>
            Hardware: Windows 11 + RTX 5060 Ti | Agente: OpenCode | Modelo: gpt-oss:20b GPU-accelerated.
        </div>
    </section>

    <section id="requisitos">
        <h2>REQUISITOS PREVIOS</h2>
        <div class="content-block">
            <h3>Hardware</h3>
            <ul>
                <li>Windows 11 actualizado</li>
                <li>NVIDIA RTX 5060 Ti (12GB VRAM) + drivers Studio/Game Ready</li>
                <li>Verificar GPU: Administrador Tareas → Rendimiento → GPU</li>
            </ul>
            
            <h3>Software</h3>
            <ul>
                <li><span class="code">Ollama</span> (servidor IA local OpenAI-compatible)</li>
                <li><span class="code">OpenCode</span> (agente de desarrollo)</li>
                <li>Red local: ping <span class="code">192.168.7.114:11434</span></li>
            </ul>
        </div>
    </section>

    <section id="servidor">
        <h2>CONFIGURACIÓN SERVIDOR IA LOCAL</h2>
        <div class="content-block">
            <ol>
                <li>Instalar Ollama: Descargar Windows → ejecutar → service auto-start</li>
                <li>Descargar modelo GPU:
                    <pre><code>ollama pull gpt-oss:20b</code></pre>
                </li>
                <li>Servicio activo: <span class="code">http://192.168.7.114:11434/v1/models</span> → lista modelos disponibles</li>
                <li>Test API: curl /v1/chat/completions → respuesta modelo local</li>
            </ol>
            <div class="nota">
                Ollama auto-detecta CUDA → carga modelo GPU RTX 5060 Ti. Logs confirman <span class="code">GPU layers loaded: 35/35</span>.
            </div>
        </div>
    </section>

    <section id="opencode">
        <h2>CONFIGURACIÓN OPENCODE</h2>
        <div class="content-block">
            <h3>Archivo <span class="code">opencode.json</span></h3>
            <div class="codigo">{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "ollama": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama GPU Local",
      "options": {
        "baseURL": "http://192.168.7.114:11434/v1"
      },
      "models": {
        "gpt-oss:20b": {
          "name": "gpt-oss:20b (RTX 5060 Ti)"
        }
      }
    }
  }
}</div>
            
            <h3>Proceso</h3>
            <ul>
                <li>Guardar <span class="code">opencode.json</span> en <span class="code">%USERPROFILE%\.opencode\</span> o proyecto</li>
                <li>OpenCode detecta "Ollama GPU Local" → seleccionar gpt-oss:20b</li>
                <li>Requests van a servidor local → inferencia GPU RTX</li>
            </ul>
        </div>
    </section>

    <section id="pruebas">
        <h2>PRUEBAS + GPU USAGE</h2>
        <div class="content-block">
            <h3>Test workflow</h3>
            <ol>
                <li>OpenCode → Seleccionar "gpt-oss:20b (RTX 5060 Ti)"</li>
                <li>Prompt: "Explica destilación IA en 3 líneas"</li>
                <li>Observar: respuesta inmediata + latencia GPU</li>
            </ol>
            
            <h3>Monitorización GPU Windows 11</h3>
            <ul>
                <li>Ctrl+Shift+Esc → Rendimiento → GPU NVIDIA RTX 5060 Ti</li>
                <li>Inferencia → picos uso GPU 40-80% + VRAM 6-9GB</li>
                <li>Logs Ollama confirman: <span class="code">GPU layers loaded: 35/35</span></li>
            </ul>
        </div>
        
        <img src="img/Captura2.png" alt="OpenCode agente + GPU monitor Windows 11">
        <div class="pie-foto">Figura 1: OpenCode conectado Ollama + Administrador Tareas mostrando GPU activa durante inferencia.</div>
        
        <img src="img/Captura1.png" alt="Logs Ollama backend GPU inference">
        <div class="pie-foto">Figura 2: Logs Ollama confirmando inferencia GPU (peticiones /v1/chat/completions + tiempos respuesta).</div>
    </section>

    <section id="conclusiones">
        <h2>CONCLUSIONES</h2>
        <div class="content-block">
            <ul>
                <li>GPU Local Activa: RTX 5060 Ti 12GB → inferencia ollama/OpenCode sin cloud</li>
                <li>API Compatible: Ollama emula OpenAI → integración directa OpenCode</li>
                <li>Monitorización Visual: Windows Task Manager → GPU usage real-time</li>
                <li>Portable Setup: opencode.json + IP servidor → multi-máquina red local</li>
                <li>Latency: ~800ms/token → viable desarrollo local</li>
            </ul>
            <hr>
            <p>ASIR Value: Configuración privada/segura para IA desarrollo → cero costes API externas.</p>
        </div>
    </section>

    <nav style="margin-top: 48px;">
        <a href="../../index.html" class="volver">← Volver al índice IA</a>
    </nav>
</body>
</html>
